{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>y17</th>\n",
       "      <th>y18</th>\n",
       "      <th>y19</th>\n",
       "      <th>y20</th>\n",
       "      <th>y21</th>\n",
       "      <th>y22</th>\n",
       "      <th>y23</th>\n",
       "      <th>y24</th>\n",
       "      <th>y25</th>\n",
       "      <th>y26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  y17  y18  y19  y20  y21  y22  \\\n",
       "0   8   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "1   7   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "2  12  10   1   1   0   0   0   4   6    0  ...    0    0    0    0    0    0   \n",
       "3  21  10   4   4   0   1   1   0   5    0  ...    0    0    0    0    0    0   \n",
       "4  27  12   3   3   0   8   0   5   0    2  ...    0    0    0    0    0    0   \n",
       "\n",
       "   y23  y24  y25  y26  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data set\n",
    "train = pd.read_csv (r'D:\\COURSES\\Winter 2021 courses\\Intelligent Analytics\\HW2\\Font_Train_DS.csv')\n",
    "test = pd.read_csv (r'D:\\COURSES\\Winter 2021 courses\\Intelligent Analytics\\HW2\\font_Test_DS.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>...</th>\n",
       "      <th>y17</th>\n",
       "      <th>y18</th>\n",
       "      <th>y19</th>\n",
       "      <th>y20</th>\n",
       "      <th>y21</th>\n",
       "      <th>y22</th>\n",
       "      <th>y23</th>\n",
       "      <th>y24</th>\n",
       "      <th>y25</th>\n",
       "      <th>y26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y1  y2  y3  y4  y5  y6  y7  y8  y9  y10  ...  y17  y18  y19  y20  y21  y22  \\\n",
       "0   1   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "1   1   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "2   1   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "3   0   1   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "4   0   1   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "\n",
       "   y23  y24  y25  y26  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Feature inputs of train dataset\n",
    "x_train = train.iloc[:,0:14]\n",
    "# x_train.head()\n",
    "y_train = train.iloc[:,14:]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>...</th>\n",
       "      <th>y17</th>\n",
       "      <th>y18</th>\n",
       "      <th>y19</th>\n",
       "      <th>y20</th>\n",
       "      <th>y21</th>\n",
       "      <th>y22</th>\n",
       "      <th>y23</th>\n",
       "      <th>y24</th>\n",
       "      <th>y25</th>\n",
       "      <th>y26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y1  y2  y3  y4  y5  y6  y7  y8  y9  y10  ...  y17  y18  y19  y20  y21  y22  \\\n",
       "0   1   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "1   1   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "2   1   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "3   0   1   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "4   0   1   0   0   0   0   0   0   0    0  ...    0    0    0    0    0    0   \n",
       "\n",
       "   y23  y24  y25  y26  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Feature inputs of test dataset\n",
    "x_test = test.iloc[:,0:14]\n",
    "# x_test.head()\n",
    "y_test = test.iloc[:,14:]\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing using standard scaler.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(52, activation='relu', input_shape=(14,)))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(26, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "78/78 [==============================] - 1s 831us/step - loss: 0.6793 - accuracy: 0.0000e+00\n",
      "Epoch 2/250\n",
      "78/78 [==============================] - 0s 784us/step - loss: 0.6509 - accuracy: 0.0000e+00\n",
      "Epoch 3/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.6193 - accuracy: 0.0000e+00\n",
      "Epoch 4/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.5741 - accuracy: 0.0000e+00\n",
      "Epoch 5/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.5478 - accuracy: 0.0000e+00\n",
      "Epoch 6/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.5133 - accuracy: 0.0000e+00\n",
      "Epoch 7/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.4794 - accuracy: 0.0000e+00\n",
      "Epoch 8/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.4345 - accuracy: 0.0000e+00\n",
      "Epoch 9/250\n",
      "78/78 [==============================] - 0s 935us/step - loss: 0.3956 - accuracy: 0.0000e+00\n",
      "Epoch 10/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.3647 - accuracy: 0.0000e+00\n",
      "Epoch 11/250\n",
      "78/78 [==============================] - 0s 886us/step - loss: 0.3359 - accuracy: 0.0000e+00\n",
      "Epoch 12/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.3157 - accuracy: 0.0000e+00\n",
      "Epoch 13/250\n",
      "78/78 [==============================] - 0s 846us/step - loss: 0.2702 - accuracy: 0.0445\n",
      "Epoch 14/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.2616 - accuracy: 0.0304\n",
      "Epoch 15/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.2400 - accuracy: 0.0177\n",
      "Epoch 16/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.2169 - accuracy: 0.0970\n",
      "Epoch 17/250\n",
      "78/78 [==============================] - 0s 886us/step - loss: 0.2136 - accuracy: 0.0291\n",
      "Epoch 18/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.2060 - accuracy: 0.0308\n",
      "Epoch 19/250\n",
      "78/78 [==============================] - 0s 846us/step - loss: 0.1977 - accuracy: 0.0764\n",
      "Epoch 20/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1863 - accuracy: 0.0819\n",
      "Epoch 21/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1896 - accuracy: 0.0365\n",
      "Epoch 22/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1766 - accuracy: 0.0387\n",
      "Epoch 23/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1765 - accuracy: 0.1168\n",
      "Epoch 24/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1685 - accuracy: 0.1143\n",
      "Epoch 25/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1692 - accuracy: 0.1950\n",
      "Epoch 26/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1661 - accuracy: 0.1371\n",
      "Epoch 27/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1672 - accuracy: 0.1327\n",
      "Epoch 28/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1594 - accuracy: 0.2448\n",
      "Epoch 29/250\n",
      "78/78 [==============================] - 0s 866us/step - loss: 0.1589 - accuracy: 0.2629\n",
      "Epoch 30/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1640 - accuracy: 0.1725\n",
      "Epoch 31/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1598 - accuracy: 0.2407\n",
      "Epoch 32/250\n",
      "78/78 [==============================] - 0s 787us/step - loss: 0.1554 - accuracy: 0.2118\n",
      "Epoch 33/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1583 - accuracy: 0.2929\n",
      "Epoch 34/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1577 - accuracy: 0.2130\n",
      "Epoch 35/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1519 - accuracy: 0.3206\n",
      "Epoch 36/250\n",
      "78/78 [==============================] - 0s 827us/step - loss: 0.1575 - accuracy: 0.1775\n",
      "Epoch 37/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1555 - accuracy: 0.1832\n",
      "Epoch 38/250\n",
      "78/78 [==============================] - 0s 775us/step - loss: 0.1520 - accuracy: 0.1766\n",
      "Epoch 39/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1526 - accuracy: 0.1493\n",
      "Epoch 40/250\n",
      "78/78 [==============================] - 0s 742us/step - loss: 0.1529 - accuracy: 0.2249\n",
      "Epoch 41/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1487 - accuracy: 0.2766\n",
      "Epoch 42/250\n",
      "78/78 [==============================] - 0s 728us/step - loss: 0.1483 - accuracy: 0.2596\n",
      "Epoch 43/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1505 - accuracy: 0.1907\n",
      "Epoch 44/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1473 - accuracy: 0.2595\n",
      "Epoch 45/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1466 - accuracy: 0.3233\n",
      "Epoch 46/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1450 - accuracy: 0.3344\n",
      "Epoch 47/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1459 - accuracy: 0.2635\n",
      "Epoch 48/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1439 - accuracy: 0.2795\n",
      "Epoch 49/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1442 - accuracy: 0.3818\n",
      "Epoch 50/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1422 - accuracy: 0.3169\n",
      "Epoch 51/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1455 - accuracy: 0.3308\n",
      "Epoch 52/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1436 - accuracy: 0.5262\n",
      "Epoch 53/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1410 - accuracy: 0.4295\n",
      "Epoch 54/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1389 - accuracy: 0.4838\n",
      "Epoch 55/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1405 - accuracy: 0.4945\n",
      "Epoch 56/250\n",
      "78/78 [==============================] - 0s 728us/step - loss: 0.1374 - accuracy: 0.4216\n",
      "Epoch 57/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1329 - accuracy: 0.4294\n",
      "Epoch 58/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1401 - accuracy: 0.4367\n",
      "Epoch 59/250\n",
      "78/78 [==============================] - 0s 772us/step - loss: 0.1429 - accuracy: 0.3939\n",
      "Epoch 60/250\n",
      "78/78 [==============================] - 0s 742us/step - loss: 0.1408 - accuracy: 0.4598\n",
      "Epoch 61/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1347 - accuracy: 0.5512\n",
      "Epoch 62/250\n",
      "78/78 [==============================] - 0s 787us/step - loss: 0.1338 - accuracy: 0.5206\n",
      "Epoch 63/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1321 - accuracy: 0.4383\n",
      "Epoch 64/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1354 - accuracy: 0.5472\n",
      "Epoch 65/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1326 - accuracy: 0.6068\n",
      "Epoch 66/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1355 - accuracy: 0.4447\n",
      "Epoch 67/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1349 - accuracy: 0.4910\n",
      "Epoch 68/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1301 - accuracy: 0.5952\n",
      "Epoch 69/250\n",
      "78/78 [==============================] - 0s 728us/step - loss: 0.1323 - accuracy: 0.5245\n",
      "Epoch 70/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1328 - accuracy: 0.4780\n",
      "Epoch 71/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1256 - accuracy: 0.6161\n",
      "Epoch 72/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1284 - accuracy: 0.5103\n",
      "Epoch 73/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1342 - accuracy: 0.5639\n",
      "Epoch 74/250\n",
      "78/78 [==============================] - 0s 935us/step - loss: 0.1240 - accuracy: 0.5955\n",
      "Epoch 75/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1293 - accuracy: 0.4625\n",
      "Epoch 76/250\n",
      "78/78 [==============================] - 0s 875us/step - loss: 0.1305 - accuracy: 0.5662\n",
      "Epoch 77/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1290 - accuracy: 0.5498\n",
      "Epoch 78/250\n",
      "78/78 [==============================] - 0s 846us/step - loss: 0.1292 - accuracy: 0.4661\n",
      "Epoch 79/250\n",
      "78/78 [==============================] - 0s 876us/step - loss: 0.1216 - accuracy: 0.6133\n",
      "Epoch 80/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1220 - accuracy: 0.6133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/250\n",
      "78/78 [==============================] - 0s 846us/step - loss: 0.1201 - accuracy: 0.5739\n",
      "Epoch 82/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1197 - accuracy: 0.7069\n",
      "Epoch 83/250\n",
      "78/78 [==============================] - 0s 728us/step - loss: 0.1217 - accuracy: 0.5892\n",
      "Epoch 84/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1250 - accuracy: 0.5336\n",
      "Epoch 85/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1243 - accuracy: 0.5271\n",
      "Epoch 86/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1212 - accuracy: 0.5716\n",
      "Epoch 87/250\n",
      "78/78 [==============================] - 0s 886us/step - loss: 0.1214 - accuracy: 0.5747\n",
      "Epoch 88/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1225 - accuracy: 0.5880\n",
      "Epoch 89/250\n",
      "78/78 [==============================] - 0s 728us/step - loss: 0.1145 - accuracy: 0.5901\n",
      "Epoch 90/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1219 - accuracy: 0.5988\n",
      "Epoch 91/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1117 - accuracy: 0.6644\n",
      "Epoch 92/250\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.5973   - 0s 788us/step - loss: 0.1145 - accuracy: 0.6007\n",
      "Epoch 93/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1181 - accuracy: 0.6592\n",
      "Epoch 94/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1129 - accuracy: 0.5913\n",
      "Epoch 95/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1165 - accuracy: 0.5406\n",
      "Epoch 96/250\n",
      "78/78 [==============================] - 0s 894us/step - loss: 0.1209 - accuracy: 0.5444\n",
      "Epoch 97/250\n",
      "78/78 [==============================] - 0s 846us/step - loss: 0.1144 - accuracy: 0.5838\n",
      "Epoch 98/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1130 - accuracy: 0.6558\n",
      "Epoch 99/250\n",
      "78/78 [==============================] - 0s 879us/step - loss: 0.1109 - accuracy: 0.6551\n",
      "Epoch 100/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1089 - accuracy: 0.6757\n",
      "Epoch 101/250\n",
      "78/78 [==============================] - 0s 846us/step - loss: 0.1093 - accuracy: 0.6627\n",
      "Epoch 102/250\n",
      "78/78 [==============================] - 0s 871us/step - loss: 0.1100 - accuracy: 0.7070\n",
      "Epoch 103/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1074 - accuracy: 0.7128\n",
      "Epoch 104/250\n",
      "78/78 [==============================] - 0s 743us/step - loss: 0.1144 - accuracy: 0.6335\n",
      "Epoch 105/250\n",
      "78/78 [==============================] - 0s 728us/step - loss: 0.1097 - accuracy: 0.7540\n",
      "Epoch 106/250\n",
      "78/78 [==============================] - 0s 846us/step - loss: 0.1122 - accuracy: 0.6665\n",
      "Epoch 107/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1071 - accuracy: 0.6966\n",
      "Epoch 108/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1092 - accuracy: 0.6419\n",
      "Epoch 109/250\n",
      "78/78 [==============================] - 0s 727us/step - loss: 0.1058 - accuracy: 0.6827\n",
      "Epoch 110/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1079 - accuracy: 0.6104\n",
      "Epoch 111/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1025 - accuracy: 0.7356\n",
      "Epoch 112/250\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.1132 - accuracy: 0.6253\n",
      "Epoch 113/250\n",
      "78/78 [==============================] - 0s 825us/step - loss: 0.1067 - accuracy: 0.6679\n",
      "Epoch 114/250\n",
      "78/78 [==============================] - 0s 846us/step - loss: 0.1062 - accuracy: 0.7154\n",
      "Epoch 115/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.5941\n",
      "Epoch 116/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.6000\n",
      "Epoch 117/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.6100\n",
      "Epoch 118/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.6807\n",
      "Epoch 119/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.6411\n",
      "Epoch 120/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.6783\n",
      "Epoch 121/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.6118\n",
      "Epoch 122/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.6745\n",
      "Epoch 123/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.6084\n",
      "Epoch 124/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.7640\n",
      "Epoch 125/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.6513\n",
      "Epoch 126/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.7583\n",
      "Epoch 127/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.7148\n",
      "Epoch 128/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.6905\n",
      "Epoch 129/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.7216\n",
      "Epoch 130/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.7617\n",
      "Epoch 131/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.6541\n",
      "Epoch 132/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.7377\n",
      "Epoch 133/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.6651\n",
      "Epoch 134/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.7644\n",
      "Epoch 135/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.6981\n",
      "Epoch 136/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.6620\n",
      "Epoch 137/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.7112\n",
      "Epoch 138/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.7095\n",
      "Epoch 139/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.7440\n",
      "Epoch 140/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.7693\n",
      "Epoch 141/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.7923\n",
      "Epoch 142/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.8126\n",
      "Epoch 143/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.7260\n",
      "Epoch 144/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.7979\n",
      "Epoch 145/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.7892\n",
      "Epoch 146/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.6955\n",
      "Epoch 147/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.7198\n",
      "Epoch 148/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.6909\n",
      "Epoch 149/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.7147\n",
      "Epoch 150/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.6946\n",
      "Epoch 151/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.7733\n",
      "Epoch 152/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.8238\n",
      "Epoch 153/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.7887\n",
      "Epoch 154/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.8466\n",
      "Epoch 155/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.7438\n",
      "Epoch 156/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.7293\n",
      "Epoch 157/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.7723\n",
      "Epoch 158/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.6903\n",
      "Epoch 159/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.7420\n",
      "Epoch 160/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.8163\n",
      "Epoch 161/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.7392\n",
      "Epoch 162/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.7925\n",
      "Epoch 163/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.7326\n",
      "Epoch 164/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.7120\n",
      "Epoch 165/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.8526\n",
      "Epoch 166/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.8635\n",
      "Epoch 167/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0831 - accuracy: 0.7819\n",
      "Epoch 168/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.7784\n",
      "Epoch 169/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.7886\n",
      "Epoch 170/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.7782\n",
      "Epoch 171/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.7926\n",
      "Epoch 172/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.7968\n",
      "Epoch 173/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.8145\n",
      "Epoch 174/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.7989\n",
      "Epoch 175/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.8141\n",
      "Epoch 176/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.8000\n",
      "Epoch 177/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.8597\n",
      "Epoch 178/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.8631\n",
      "Epoch 179/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.8971\n",
      "Epoch 180/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.7783\n",
      "Epoch 181/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.8300\n",
      "Epoch 182/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.8768\n",
      "Epoch 183/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.8642\n",
      "Epoch 184/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.8456\n",
      "Epoch 185/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.8972\n",
      "Epoch 186/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.8149\n",
      "Epoch 187/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.8031\n",
      "Epoch 188/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.8105\n",
      "Epoch 189/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9017\n",
      "Epoch 190/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.8236\n",
      "Epoch 191/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.8489\n",
      "Epoch 192/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.8608\n",
      "Epoch 193/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.8817\n",
      "Epoch 194/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.8511\n",
      "Epoch 195/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.8593\n",
      "Epoch 196/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.8806\n",
      "Epoch 197/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.8827\n",
      "Epoch 198/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.8589\n",
      "Epoch 199/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9450\n",
      "Epoch 200/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.8473\n",
      "Epoch 201/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.8668\n",
      "Epoch 202/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.8849\n",
      "Epoch 203/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9124\n",
      "Epoch 204/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.8916\n",
      "Epoch 205/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.8282\n",
      "Epoch 206/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9123\n",
      "Epoch 207/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.8990\n",
      "Epoch 208/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9151\n",
      "Epoch 209/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.9060\n",
      "Epoch 210/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9139\n",
      "Epoch 211/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9161\n",
      "Epoch 212/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.8545\n",
      "Epoch 213/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9243\n",
      "Epoch 214/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9371\n",
      "Epoch 215/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9510\n",
      "Epoch 216/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9166\n",
      "Epoch 217/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9038\n",
      "Epoch 218/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.8904\n",
      "Epoch 219/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9606\n",
      "Epoch 220/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9613\n",
      "Epoch 221/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9144\n",
      "Epoch 222/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9146\n",
      "Epoch 223/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9411\n",
      "Epoch 224/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9454\n",
      "Epoch 225/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9655\n",
      "Epoch 226/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9655\n",
      "Epoch 227/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9578\n",
      "Epoch 228/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9682\n",
      "Epoch 229/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.8996\n",
      "Epoch 230/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9542\n",
      "Epoch 231/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9196\n",
      "Epoch 232/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9645\n",
      "Epoch 233/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9725\n",
      "Epoch 234/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9532\n",
      "Epoch 235/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9492\n",
      "Epoch 236/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9316\n",
      "Epoch 237/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9471\n",
      "Epoch 238/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9382\n",
      "Epoch 239/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9873\n",
      "Epoch 240/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9818\n",
      "Epoch 241/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9898\n",
      "Epoch 242/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9412\n",
      "Epoch 243/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9832\n",
      "Epoch 244/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9762\n",
      "Epoch 245/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9461\n",
      "Epoch 246/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9488\n",
      "Epoch 247/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9621\n",
      "Epoch 248/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9800\n",
      "Epoch 249/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9734\n",
      "Epoch 250/250\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bdddfe0490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "model.fit(x_train, y_train,epochs=250, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     weights = layer.get_weights()\n",
    "#     print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kavya\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Running predictions on test dataset\n",
    "y_pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step - loss: 0.0739 - accuracy: 0.8205\n",
      "[0.07389461994171143, 0.8205128312110901]\n"
     ]
    }
   ],
   "source": [
    "# computing accuracy\n",
    "score = model.evaluate(x_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
